{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-02-05T02:12:01.203Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing JSON\n",
    "There are several packages that provide JSON parsing API. Here, we use the  [Play Framework](https://www.playframework.com/) API https://www.playframework.com/documentation/2.1.1/ScalaJson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DateTime processing\n",
    "Dealing with dates and times can become quite complex. We use the http://www.joda.org/joda-time/ package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-05T16:38:16.771512",
     "start_time": "2017-02-05T21:38:15.805Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val DATADIR = \"/user/pmolnar/yelp/data\"\n",
    "import play.api.libs.json._\n",
    "import org.joda.time._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types.{StructType,StructField,StringType,IntegerType,FloatType,DateType};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T21:06:58.180750",
     "start_time": "2017-02-05T02:06:57.909Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_review(s:String) = {\n",
    "    val elem = Json.parse(s)\n",
    "    val dt = DateTime.parse((elem \\ \"date\").as[String])\n",
    "    Row(\n",
    "         (elem \\ \"business_id\").as[String]\n",
    "        ,(elem \\ \"user_id\").as[String]\n",
    "        ,(elem \\ \"review_id\").as[String]\n",
    "        ,dt\n",
    "        ,(elem \\ \"text\").as[String]\n",
    "        ,(elem \\ \"stars\").as[Float]\n",
    "        ,(elem \\ \"votes\" \\ \"funny\").as[Int]\n",
    "        ,(elem \\ \"votes\" \\ \"useful\").as[Int]\n",
    "        ,(elem \\ \"votes\" \\ \"cool\").as[Int]\n",
    "    )\n",
    "}\n",
    "\n",
    "val schema = StructType(Seq(\n",
    "     StructField(\"business_id\", StringType, false)\n",
    "     ,StructField(\"user_id\", StringType, false)\n",
    "     ,StructField(\"review_id\", StringType, false)\n",
    "     ,StructField(\"date\", DateType, false)\n",
    "     ,StructField(\"text\", StringType, false)\n",
    "     ,StructField(\"stars\", FloatType, false)\n",
    "     ,StructField(\"votes_funny\", IntegerType, false)\n",
    "     ,StructField(\"votes_useful\", IntegerType, false)\n",
    "     ,StructField(\"votes_cool\", IntegerType, false)\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T21:03:15.304551",
     "start_time": "2017-02-05T02:03:11.523Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val df = sqlContext.read.json(DATADIR+\"/review/review_aa.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T21:03:25.446297",
     "start_time": "2017-02-05T02:03:25.309Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- votes: struct (nullable = true)\n",
      " |    |-- cool: long (nullable = true)\n",
      " |    |-- funny: long (nullable = true)\n",
      " |    |-- useful: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T21:07:07.068710",
     "start_time": "2017-02-05T02:07:06.926Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val review_rdd = sc.textFile(DATADIR+\"/review/review_aa.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T21:07:10.945181",
     "start_time": "2017-02-05T02:07:10.598Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val review_df = sqlContext.createDataFrame(review_rdd.map(parse_review), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T21:07:20.225930",
     "start_time": "2017-02-05T02:07:20.110Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = false)\n",
      " |-- user_id: string (nullable = false)\n",
      " |-- review_id: string (nullable = false)\n",
      " |-- date: date (nullable = false)\n",
      " |-- text: string (nullable = false)\n",
      " |-- stars: float (nullable = false)\n",
      " |-- votes_funny: integer (nullable = false)\n",
      " |-- votes_useful: integer (nullable = false)\n",
      " |-- votes_cool: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T21:11:17.555193",
     "start_time": "2017-02-05T02:11:17.143Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.SparkException\n",
       "Message: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 4, localhost): java.lang.ClassCastException: org.joda.time.DateTime cannot be cast to java.sql.Date\n",
       "\tat org.apache.spark.sql.catalyst.CatalystTypeConverters$DateConverter$.toCatalystImpl(CatalystTypeConverters.scala:305)\n",
       "\tat org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)\n",
       "\tat org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:260)\n",
       "\tat org.apache.spark.sql.catalyst.CatalystTypeConverters$StructConverter.toCatalystImpl(CatalystTypeConverters.scala:250)\n",
       "\tat org.apache.spark.sql.catalyst.CatalystTypeConverters$CatalystTypeConverter.toCatalyst(CatalystTypeConverters.scala:102)\n",
       "\tat org.apache.spark.sql.catalyst.CatalystTypeConverters$$anonfun$createToCatalystConverter$2.apply(CatalystTypeConverters.scala:401)\n",
       "\tat org.apache.spark.sql.SQLContext$$anonfun$6.apply(SQLContext.scala:492)\n",
       "\tat org.apache.spark.sql.SQLContext$$anonfun$6.apply(SQLContext.scala:492)\n",
       "\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n",
       "\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n",
       "\tat org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.processInputs(TungstenAggregationIterator.scala:505)\n",
       "\tat org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.<init>(TungstenAggregationIterator.scala:686)\n",
       "\tat org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:95)\n",
       "\tat org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:86)\n",
       "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$22.apply(RDD.scala:717)\n",
       "\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$22.apply(RDD.scala:717)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:313)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:277)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:313)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:277)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "\tat java.lang.Thread.run(Thread.java:745)\n",
       "\n",
       "Driver stacktrace:\n",
       "StackTrace: org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
       "scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
       "scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
       "org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n",
       "scala.Option.foreach(Option.scala:236)\n",
       "org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
       "org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
       "org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1855)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1868)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1881)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1952)\n",
       "org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:934)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
       "org.apache.spark.rdd.RDD.withScope(RDD.scala:323)\n",
       "org.apache.spark.rdd.RDD.collect(RDD.scala:933)\n",
       "org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:166)\n",
       "org.apache.spark.sql.execution.SparkPlan.executeCollectPublic(SparkPlan.scala:174)\n",
       "org.apache.spark.sql.DataFrame$$anonfun$org$apache$spark$sql$DataFrame$$execute$1$1.apply(DataFrame.scala:1499)\n",
       "org.apache.spark.sql.DataFrame$$anonfun$org$apache$spark$sql$DataFrame$$execute$1$1.apply(DataFrame.scala:1499)\n",
       "org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:56)\n",
       "org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:2086)\n",
       "org.apache.spark.sql.DataFrame.org$apache$spark$sql$DataFrame$$execute$1(DataFrame.scala:1498)\n",
       "org.apache.spark.sql.DataFrame.org$apache$spark$sql$DataFrame$$collect(DataFrame.scala:1505)\n",
       "org.apache.spark.sql.DataFrame$$anonfun$count$1.apply(DataFrame.scala:1515)\n",
       "org.apache.spark.sql.DataFrame$$anonfun$count$1.apply(DataFrame.scala:1514)\n",
       "org.apache.spark.sql.DataFrame.withCallback(DataFrame.scala:2099)\n",
       "org.apache.spark.sql.DataFrame.count(DataFrame.scala:1514)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:50)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:55)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:57)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:59)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:61)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:63)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:65)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:69)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:71)\n",
       "$line479.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:73)\n",
       "$line479.$read$$iwC$$iwC$$iwC.<init>(<console>:75)\n",
       "$line479.$read$$iwC$$iwC.<init>(<console>:77)\n",
       "$line479.$read$$iwC.<init>(<console>:79)\n",
       "$line479.$read.<init>(<console>:81)\n",
       "$line479.$read$.<init>(<console>:85)\n",
       "$line479.$read$.<clinit>(<console>)\n",
       "$line479.$eval$.<init>(<console>:7)\n",
       "$line479.$eval$.<clinit>(<console>)\n",
       "$line479.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:497)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:04:36.504813",
     "start_time": "2017-02-05T01:04:07.625Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/review/review_aa.json.gz -> 268506\n",
      "/review/review_ab.json.gz -> 268506\n",
      "/review/review_ac.json.gz -> 101571\n",
      "/review/review_ad.json.gz -> 268506\n",
      "/review/review_ae.json.gz -> 268506\n",
      "/review/review_af.json.gz -> 268506\n",
      "/review/review_ag.json.gz -> 268506\n",
      "/review/review_ah.json.gz -> 268506\n",
      "/review/review_ai.json.gz -> 268506\n",
      "/review/review_aj.json.gz -> 268506\n",
      "/review/review_ak.json.gz -> 6\n"
     ]
    }
   ],
   "source": [
    "for (k <- ('a' to 'k')) {\n",
    "    val fn = \"/review/review_a\"+k+\".json.gz\"\n",
    "    val review_rdd = sc.textFile(DATADIR+fn)\n",
    "    val n = review_rdd.map(parse_review).map(t => (t._6, t._5.length)).count\n",
    "    println(fn+\" -> \"+n)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T19:59:21.118516",
     "start_time": "2017-02-05T00:59:15.909Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268506\n"
     ]
    }
   ],
   "source": [
    "for (val review_rdd = sc.textFile(DATADIR+\"/review/review_aa.json.gz\")\n",
    "val n = review_rdd.map(parse_review).map(t => (t._6, t._5.length)).count\n",
    "println(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:04:59.463943",
     "start_time": "2017-02-04T21:04:58.619Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array({\"votes\": {\"funny\": 0, \"useful\": 0, \"cool\": 0}, \"user_id\": \"PUFPaY9KxDAcGqfsorJp3Q\", \"review_id\": \"Ya85v4eqdd6k9Od8HbQjyA\", \"stars\": 4, \"date\": \"2012-08-01\", \"text\": \"Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.\", \"type\": \"review\", \"business_id\": \"5UmKMjUEUNdYWqANhGckJw\"})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:06:58.185684",
     "start_time": "2017-02-04T21:06:57.927Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"votes\": {\"funny\": 0, \"useful\": 0, \"cool\": 0}, \"user_id\": \"PUFPaY9KxDAcGqfsorJp3Q\", \"review_id\": \"Ya85v4eqdd6k9Od8HbQjyA\", \"stars\": 4, \"date\": \"2012-08-01\", \"text\": \"Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.\", \"type\": \"review\", \"business_id\": \"5UmKMjUEUNdYWqANhGckJw\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_rdd.take(1)(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T19:59:10.608392",
     "start_time": "2017-02-05T00:59:10.477Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import play.api.libs.json._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:47:52.755488",
     "start_time": "2017-02-05T01:47:52.580Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:41:39.965518",
     "start_time": "2017-02-05T01:41:39.865Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types.{StructType,StructField,StringType,IntegerType,FloatType,DateType};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:47:55.238586",
     "start_time": "2017-02-05T01:47:55.116Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val schema = StructType(List(\n",
    "     StructField(\"business_id\", StringType, false)\n",
    "    ,StructField(\"user_id\", StringType, false)\n",
    "    ,StructField(\"review_id\", StringType, false)\n",
    "    ,StructField(\"date\", DateType, false)\n",
    "    ,StructField(\"text\", StringType, false)\n",
    "    ,StructField(\"stars\", FloatType, false)\n",
    "    ,StructField(\"votes_funny\", IntegerType, false)\n",
    "    ,StructField(\"votes_useful\", IntegerType, false)\n",
    "    ,StructField(\"votes_cool\", IntegerType, false)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:45:51.702027",
     "start_time": "2017-02-05T01:45:51.579Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val review_tup_rdd = review_rdd.map(parse_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:47:08.226035",
     "start_time": "2017-02-05T01:47:08.099Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:48:24.605513",
     "start_time": "2017-02-05T01:48:24.507Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:49: error: overloaded method value createDataFrame with alternatives:\n",
       "  (data: java.util.List[_],beanClass: Class[_])org.apache.spark.sql.DataFrame <and>\n",
       "  (rdd: org.apache.spark.api.java.JavaRDD[_],beanClass: Class[_])org.apache.spark.sql.DataFrame <and>\n",
       "  (rdd: org.apache.spark.rdd.RDD[_],beanClass: Class[_])org.apache.spark.sql.DataFrame <and>\n",
       "  (rows: java.util.List[org.apache.spark.sql.Row],schema: org.apache.spark.sql.types.StructType)org.apache.spark.sql.DataFrame <and>\n",
       "  (rowRDD: org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row],schema: org.apache.spark.sql.types.StructType)org.apache.spark.sql.DataFrame <and>\n",
       "  (rowRDD: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row],schema: org.apache.spark.sql.types.StructType)org.apache.spark.sql.DataFrame\n",
       " cannot be applied to (org.apache.spark.rdd.RDD[(String, String, String, org.joda.time.DateTime, String, Float)], org.apache.spark.sql.types.StructType)\n",
       "         val review_df = sqlContext.createDataFrame(review_tup_rdd, schema)\n",
       "                                    ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val review_df = sqlContext.createDataFrame(review_rdd.map(parse_review), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:31:47.233504",
     "start_time": "2017-02-05T01:31:46.912Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val t = review_rdd.map(parse_review).sample(false, 0.1).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:31:54.735650",
     "start_time": "2017-02-05T01:31:54.611Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val r = Json.parse(review_rdd.take(1)(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:31:56.415718",
     "start_time": "2017-02-05T01:31:56.298Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"funny\":0,\"useful\":0,\"cool\":0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r \\ \"votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:27:21.330879",
     "start_time": "2017-02-05T01:27:21.204Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_rdd.map(parse_review).map(t => (t._6, t._5.length)).dependencies.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:27:00.510195",
     "start_time": "2017-02-05T01:27:00.379Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org.apache.spark.OneToOneDependency@38fc3be1\n"
     ]
    }
   ],
   "source": [
    "for (s <- dep1) println(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:41:07.752186",
     "start_time": "2017-02-04T21:41:07.338Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(mr, hoagie, is, an, institution., walking, in,, it, does, seem, like, a, throwback, to, 30, years, ago,, old, fashioned, menu, board,, booths, out, of, the, 70s,, and, a, large, selection, of, food., their, speciality, is, the, italian, hoagie,, and, it, is, voted, the, best, in, the, area, year, after, year., i, usually, order, the, burger,, while, the, patties, are, obviously, cooked, from, frozen,, all, of, the, other, ingredients, are, very, fresh., overall,, its, a, good, alternative, to, subway,, which, is, down, the, road.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(elem \\ \"text\").as[String].split(' ').map(x => x.toLowerCase())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:42:56.205699",
     "start_time": "2017-02-04T21:42:56.038Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abs23432"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"  abs23432  \".toString."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:44:59.145715",
     "start_time": "2017-02-04T21:44:58.959Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(elem \\ \"stars\").as[Double]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T19:36:26.974790",
     "start_time": "2017-02-05T00:36:26.859Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def foo(x: Int): Int = {\n",
    "    return x*x\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T19:36:39.008362",
     "start_time": "2017-02-05T00:36:38.907Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54756"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T19:35:51.903782",
     "start_time": "2017-02-05T00:35:51.831Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scala.Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T19:39:15.479870",
     "start_time": "2017-02-05T00:39:15.314Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def boo(x: List[Any]) {\n",
    "    for(a <- x) {\n",
    "        println(a)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T19:39:54.187489",
     "start_time": "2017-02-05T00:39:54.009Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n",
      "dsf\n",
      "234.0\n"
     ]
    }
   ],
   "source": [
    "boo(List(234, \"dsf\", 234.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:20:32.740905",
     "start_time": "2017-02-04T21:20:32.563Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val row = review_rdd.take(1)(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:32:53.910676",
     "start_time": "2017-02-04T21:32:53.629Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.lang.ClassCastException\n",
       "Message: scala.Some cannot be cast to scala.collection.immutable.Map\n",
       "StackTrace: $line386.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)\n",
       "$line386.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:40)\n",
       "$line386.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:42)\n",
       "$line386.$read$$iwC$$iwC$$iwC.<init>(<console>:44)\n",
       "$line386.$read$$iwC$$iwC.<init>(<console>:46)\n",
       "$line386.$read$$iwC.<init>(<console>:48)\n",
       "$line386.$read.<init>(<console>:50)\n",
       "$line386.$read$.<init>(<console>:54)\n",
       "$line386.$read$.<clinit>(<console>)\n",
       "$line386.$eval$.<init>(<console>:7)\n",
       "$line386.$eval$.<clinit>(<console>)\n",
       "$line386.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:497)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem.asInstanceOf[Map[String, Any]](\"votes\").asInstanceOf[Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:24:18.810029",
     "start_time": "2017-02-04T21:24:18.695Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:1: error: illegal start of simple expression\n",
       "       (val k in elem)\n",
       "        ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val k in elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:16:35.244336",
     "start_time": "2017-02-04T21:16:35.091Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"votes\":{\"funny\":0,\"useful\":0,\"cool\":0},\"user_id\":\"PUFPaY9KxDAcGqfsorJp3Q\",\"review_id\":\"Ya85v4eqdd6k9Od8HbQjyA\",\"stars\":4,\"date\":\"2012-08-01\",\"text\":\"Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.\",\"type\":\"review\",\"business_id\":\"5UmKMjUEUNdYWqANhGckJw\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem.toString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T16:19:08.668932",
     "start_time": "2017-02-04T21:19:08.500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"votes\":{\"funny\":0,\"useful\":0,\"cool\":0},\"user_id\":\"PUFPaY9KxDAcGqfsorJp3Q\",\"review_id\":\"Ya85v4eqdd6k9Od8HbQjyA\",\"stars\":4,\"date\":\"2012-08-01\",\"text\":\"Mr Hoagie is an institution. Walking in, it does seem like a throwback to 30 years ago, old fashioned menu board, booths out of the 70s, and a large selection of food. Their speciality is the Italian Hoagie, and it is voted the best in the area year after year. I usually order the burger, while the patties are obviously cooked from frozen, all of the other ingredients are very fresh. Overall, its a good alternative to Subway, which is down the road.\",\"type\":\"review\",\"business_id\":\"5UmKMjUEUNdYWqANhGckJw\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:19:08.998718",
     "start_time": "2017-02-05T01:19:08.855Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.joda.time._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:15:16.355491",
     "start_time": "2017-02-05T01:15:16.234Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-08-01T00:00:00.000-04:00"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org.joda.time.DateTime.parse(\"2012-08-01\") //.withZone(org.joda.time.DateTimeZone.forOffsetHours(-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:12:11.688550",
     "start_time": "2017-02-05T01:12:11.604Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.joda.time.DateTimeZone._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:14:14.479123",
     "start_time": "2017-02-05T01:14:14.384Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-05:00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org.joda.time.DateTimeZone.forOffsetHours(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-04T20:18:34.904576",
     "start_time": "2017-02-05T01:18:34.721Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-08-01T00:00:00.000-04:00"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(\"2012-08-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-05T16:39:24.115822",
     "start_time": "2017-02-05T21:39:21.167Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val user_df = sqlContext.read.json(\"/user/pmolnar/yelp/data/user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-05T16:39:31.197635",
     "start_time": "2017-02-05T21:39:30.984Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliments: struct (nullable = true)\n",
      " |    |-- cool: long (nullable = true)\n",
      " |    |-- cute: long (nullable = true)\n",
      " |    |-- funny: long (nullable = true)\n",
      " |    |-- hot: long (nullable = true)\n",
      " |    |-- list: long (nullable = true)\n",
      " |    |-- more: long (nullable = true)\n",
      " |    |-- note: long (nullable = true)\n",
      " |    |-- photos: long (nullable = true)\n",
      " |    |-- plain: long (nullable = true)\n",
      " |    |-- profile: long (nullable = true)\n",
      " |    |-- writer: long (nullable = true)\n",
      " |-- elite: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- fans: long (nullable = true)\n",
      " |-- friends: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- votes: struct (nullable = true)\n",
      " |    |-- cool: long (nullable = true)\n",
      " |    |-- funny: long (nullable = true)\n",
      " |    |-- useful: long (nullable = true)\n",
      " |-- yelping_since: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-05T16:43:40.439854",
     "start_time": "2017-02-05T21:43:40.174Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val u = user_df.take(1)(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
