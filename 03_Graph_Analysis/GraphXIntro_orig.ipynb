{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "- Scala Cheat Sheet http://docs.scala-lang.org/cheatsheets/\n",
    "- Scala by Example https://www.scala-lang.org/old/sites/default/files/linuxsoft_archives/docu/files/ScalaByExample.pdf\n",
    "- GraphX Programming Guide http://spark.apache.org/docs/1.6.1/graphx-programming-guide.html\n",
    "- Spark GraphX in Action https://www.manning.com/books/spark-graphx-in-action ([source code](https://manning-content.s3.amazonaws.com/download/3/6311f4a-a8af-45e2-80d1-f4689c23d802/SparkGraphXInActionSourceCode.zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-02-24T16:40:03.921Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"Monitor this application at http://arc.insight.gsu.edu:8088/proxy/\"+sc.applicationId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-24T11:39:24.508620",
     "start_time": "2017-02-24T16:39:22.579Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.lang.IllegalStateException\n",
       "Message: Cannot call methods on a stopped SparkContext.\n",
       "This stopped SparkContext was created at:\n",
       "\n",
       "org.apache.spark.SparkContext.<init>(SparkContext.scala:82)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply$mcV$sp(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.api.Kernel.initializeSparkContext(Kernel.scala:395)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:349)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:370)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:101)\n",
       "org.apache.toree.Main$$anon$1.initializeSparkContext(Main.scala:35)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:86)\n",
       "org.apache.toree.Main$$anon$1.initializeComponents(Main.scala:35)\n",
       "org.apache.toree.boot.KernelBootstrap.initialize(KernelBootstrap.scala:89)\n",
       "org.apache.toree.Main$delayedInit$body.apply(Main.scala:40)\n",
       "scala.Function0$class.apply$mcV$sp(Function0.scala:40)\n",
       "scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)\n",
       "\n",
       "The currently active SparkContext was created at:\n",
       "\n",
       "org.apache.spark.SparkContext.<init>(SparkContext.scala:82)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply$mcV$sp(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.api.Kernel.initializeSparkContext(Kernel.scala:395)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:349)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:370)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:101)\n",
       "org.apache.toree.Main$$anon$1.initializeSparkContext(Main.scala:35)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:86)\n",
       "org.apache.toree.Main$$anon$1.initializeComponents(Main.scala:35)\n",
       "org.apache.toree.boot.KernelBootstrap.initialize(KernelBootstrap.scala:89)\n",
       "org.apache.toree.Main$delayedInit$body.apply(Main.scala:40)\n",
       "scala.Function0$class.apply$mcV$sp(Function0.scala:40)\n",
       "scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)\n",
       "         \n",
       "StackTrace: org.apache.spark.SparkContext.org$apache$spark$SparkContext$$assertNotStopped(SparkContext.scala:106)\n",
       "org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:2109)\n",
       "org.apache.spark.SparkContext.defaultMinPartitions(SparkContext.scala:2122)\n",
       "org.apache.spark.SparkContext.textFile$default$2(SparkContext.scala:830)\n",
       "org.apache.spark.graphx.GraphLoader$.edgeListFile(GraphLoader.scala:72)\n",
       "$line48.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n",
       "$line48.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:34)\n",
       "$line48.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:36)\n",
       "$line48.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:38)\n",
       "$line48.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:40)\n",
       "$line48.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:42)\n",
       "$line48.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:44)\n",
       "$line48.$read$$iwC$$iwC$$iwC.<init>(<console>:46)\n",
       "$line48.$read$$iwC$$iwC.<init>(<console>:48)\n",
       "$line48.$read$$iwC.<init>(<console>:50)\n",
       "$line48.$read.<init>(<console>:52)\n",
       "$line48.$read$.<init>(<console>:56)\n",
       "$line48.$read$.<clinit>(<console>)\n",
       "$line48.$eval$.<init>(<console>:7)\n",
       "$line48.$eval$.<clinit>(<console>)\n",
       "$line48.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:497)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.graphx._\n",
    "val graph = GraphLoader.edgeListFile(sc, \"/user/pmolnar/graphx/cit-HepTh.txt.gz\")\n",
    "graph.inDegrees.reduce((a,b) => if (a._2 > b._2) a else b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-24T11:37:44.417893",
     "start_time": "2017-02-24T16:37:44.208Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_1487525026281_0010\n"
     ]
    }
   ],
   "source": [
    "println(sc.applicationId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-24T11:37:14.500943",
     "start_time": "2017-02-24T16:36:45.570Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.SparkException\n",
       "Message: Job aborted due to stage failure: Task serialization failed: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\n",
       "This stopped SparkContext was created at:\n",
       "\n",
       "org.apache.spark.SparkContext.<init>(SparkContext.scala:82)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply$mcV$sp(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.api.Kernel.initializeSparkContext(Kernel.scala:395)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:349)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:370)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:101)\n",
       "org.apache.toree.Main$$anon$1.initializeSparkContext(Main.scala:35)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:86)\n",
       "org.apache.toree.Main$$anon$1.initializeComponents(Main.scala:35)\n",
       "org.apache.toree.boot.KernelBootstrap.initialize(KernelBootstrap.scala:89)\n",
       "org.apache.toree.Main$delayedInit$body.apply(Main.scala:40)\n",
       "scala.Function0$class.apply$mcV$sp(Function0.scala:40)\n",
       "scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)\n",
       "\n",
       "The currently active SparkContext was created at:\n",
       "\n",
       "org.apache.spark.SparkContext.<init>(SparkContext.scala:82)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply$mcV$sp(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.api.Kernel.initializeSparkContext(Kernel.scala:395)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:349)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:370)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:101)\n",
       "org.apache.toree.Main$$anon$1.initializeSparkContext(Main.scala:35)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:86)\n",
       "org.apache.toree.Main$$anon$1.initializeComponents(Main.scala:35)\n",
       "org.apache.toree.boot.KernelBootstrap.initialize(KernelBootstrap.scala:89)\n",
       "org.apache.toree.Main$delayedInit$body.apply(Main.scala:40)\n",
       "scala.Function0$class.apply$mcV$sp(Function0.scala:40)\n",
       "scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)\n",
       "         \n",
       "org.apache.spark.SparkContext.org$apache$spark$SparkContext$$assertNotStopped(SparkContext.scala:106)\n",
       "org.apache.spark.SparkContext.broadcast(SparkContext.scala:1342)\n",
       "org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1006)\n",
       "org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:921)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:924)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:923)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:923)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:924)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:923)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:923)\n",
       "org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:861)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1607)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
       "org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
       "\n",
       "StackTrace: org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n",
       "scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
       "scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n",
       "org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n",
       "org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1016)\n",
       "org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:921)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:924)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:923)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:923)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:924)\n",
       "org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:923)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:923)\n",
       "org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:861)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1607)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n",
       "org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n",
       "org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
       "org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1855)\n",
       "org.apache.spark.SparkContext.runJob(SparkContext.scala:1975)\n",
       "org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1032)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n",
       "org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n",
       "org.apache.spark.rdd.RDD.withScope(RDD.scala:323)\n",
       "org.apache.spark.rdd.RDD.reduce(RDD.scala:1014)\n",
       "org.apache.spark.graphx.impl.VertexRDDImpl.count(VertexRDDImpl.scala:90)\n",
       "org.apache.spark.graphx.Pregel$.apply(Pregel.scala:143)\n",
       "org.apache.spark.graphx.lib.PageRank$.runUntilConvergenceWithOptions(PageRank.scala:260)\n",
       "org.apache.spark.graphx.lib.PageRank$.runUntilConvergence(PageRank.scala:178)\n",
       "org.apache.spark.graphx.GraphOps.pageRank(GraphOps.scala:372)\n",
       "$line27.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:28)\n",
       "$line27.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n",
       "$line27.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)\n",
       "$line27.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)\n",
       "$line27.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)\n",
       "$line27.$read$$iwC$$iwC$$iwC.<init>(<console>:41)\n",
       "$line27.$read$$iwC$$iwC.<init>(<console>:43)\n",
       "$line27.$read$$iwC.<init>(<console>:45)\n",
       "$line27.$read.<init>(<console>:47)\n",
       "$line27.$read$.<init>(<console>:51)\n",
       "$line27.$read$.<clinit>(<console>)\n",
       "$line27.$eval$.<init>(<console>:7)\n",
       "$line27.$eval$.<clinit>(<console>)\n",
       "$line27.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:497)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.graphx._\n",
    "val graph = GraphLoader.edgeListFile(sc, \"/user/pmolnar/graphx/cit-HepTh.txt.gz\")\n",
    "val v = graph.pageRank(0.001).vertices\n",
    "v.reduce((a,b) => if (a._2 > b._2) a else b)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  },
  "toc": {
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
